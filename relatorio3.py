# -*- coding: utf-8 -*-
"""relatorio3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/Magnolgm/bc016d3a79c1ed03a67a7531d1cfd553/relatorio3.ipynb

Nomes: Paulo Henrique Silva Dias RA:156648

MAGNO LUIZ GONCALVES MELO : 133688

#Inicialização do Projeto e descrição dos dados
Atribuindo libs para análise
"""

# Commented out IPython magic to ensure Python compatibility.
#Montagem drive
from google.colab import drive
drive.mount('/content/drive')

#Inicialização de bibliotecas para analise
import numpy as np

from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
# data processing
import pandas as pd


# data visualization
import seaborn as sns
# %matplotlib inline
from matplotlib import style
import plotly.graph_objs as go
import plotly.express as px
import matplotlib.pyplot as plt

"""Localização da base de dados

fonte:
https://www.kaggle.com/datasets/uom190346a/sleep-health-and-lifestyle-dataset/data

Sobre a base de dados:

A base de dados consiste em um csv de aproximadamente 400 rows e leva em consideração as seguintes classes/características:
Gênero, idade, profissão, duração do sono, qualidade do sono, nível de atividade física, nível de stress, BMI Category/IMC(classificação: acima do peso, normal, obeso), pressão sanguínea, batimentos cardiacos, passos diários e por fim o apontamento se pessoa possui insônia(classificação: Apneia do sono, insônia, sem disturbio de sono).

Principais recursos do conjunto de dados:
Métricas abrangentes do sono: explore a duração, a qualidade e os fatores que influenciam os padrões de sono.

Fatores de estilo de vida: analise os níveis de atividade física, níveis de estresse e categorias de IMC.

Saúde Cardiovascular: Examine as medições de pressão arterial e frequência cardíaca.

Análise de Distúrbios do Sono: Identifique a ocorrência de distúrbios do sono, como Insônia e Apnéia do Sono.

Colunas do conjunto de dados:
ID da pessoa: um identificador para cada indivíduo.

Gênero: O gênero da pessoa (Masculino/Feminino).

Idade: A idade da pessoa em anos.

Ocupação: A ocupação ou profissão da pessoa.

Duração do sono (horas): O número de horas que a pessoa dorme por dia.

Qualidade do Sono (escala: 1-10): Uma classificação subjetiva da qualidade do sono, variando de 1 a 10.

Nível de atividade física (minutos/dia): O número de minutos que a pessoa pratica atividade física diariamente.

Nível de Estresse (escala: 1-10): Uma classificação subjetiva do nível de estresse vivenciado pela pessoa, variando de 1 a 10.

Categoria de IMC: A categoria de IMC da pessoa (por exemplo, Abaixo do Peso, Normal, Sobrepeso).

Pressão Arterial (sistólica/diastólica): A medição da pressão arterial da pessoa, indicada como pressão sistólica sobre pressão diastólica.

Frequência cardíaca (bpm): A frequência cardíaca em repouso da pessoa em batimentos por minuto.

Passos Diários: O número de passos que a pessoa dá por dia.

Distúrbio do Sono: A presença ou ausência de um distúrbio do sono na pessoa (Nenhum, Insônia, Apnéia do Sono).


Detalhes sobre a coluna Distúrbios do Sono:

Nenhum: O indivíduo não apresenta nenhum distúrbio específico do sono.

Insônia: O indivíduo tem dificuldade em adormecer ou permanecer dormindo, levando a um sono inadequado ou de má qualidade.

Apnéia do Sono: O indivíduo sofre pausas na respiração durante o sono, resultando em padrões de sono interrompidos e riscos potenciais à saúde.


Original description:

Dataset Overview:
The Sleep Health and Lifestyle Dataset comprises 400 rows and 13 columns, covering a wide range of variables related to sleep and daily habits. It includes details such as gender, age, occupation, sleep duration, quality of sleep, physical activity level, stress levels, BMI category, blood pressure, heart rate, daily steps, and the presence or absence of sleep disorders.


"""

#leitura dos dados
data = pd.read_csv('/content/drive/MyDrive/Sleep_health_and_lifestyle_dataset.csv')

#descrição dos dados
data.head()

"""# Data info: colunas, null values, type"""

data.info()

data.describe()

#linhas e colunas
data.shape

# formato dos dados (object,int,float,etc)
data.dtypes

data.columns.values

"""#Visualização dos dados"""

def plotly_boxplot(df , numeric_types , color  , row = None) :
    def gather( df, key, value, cols ):
        id_vars = [ col for col in df.columns if col not in cols ]
        id_values = cols
        var_name = key
        value_name = value
        return pd.melt( df, id_vars, id_values, var_name, value_name )
    numeric_gather = gather( df , 'key', 'value', numeric_types )
    fig = px.box(numeric_gather, x="key", y="value",
                 facet_col="key" ,color = color ,
                 facet_row=row )
    fig.update_yaxes(showticklabels=True , matches=None)
    fig.update_xaxes(showticklabels=True , matches=None)
    fig.show()

import plotly.express as px

def plotly_countplot(df, category, title, xlabel, ylabel):
    # Get the qualitative color palette
    palette = px.colors.qualitative.Plotly

    # Generate a list of colors, one for each unique category
    unique_categories = df[category].unique()
    num_colors = len(unique_categories)
    colors = palette[:num_colors]

    fig = px.histogram(df, x=category, color=category,
                     color_discrete_map=dict(zip(unique_categories, colors)))
    fig.update_layout(title=title, xaxis_title=xlabel, yaxis_title=ylabel)
    fig.show()

def plotly_scatter(df , numerical_column_one, numerical_column_two ,
                   color = None  , row = None , col =None) :
    fig = px.scatter(df,
                     x=numerical_column_one,
                     y=numerical_column_two,
                     facet_col=col,
                     color = color ,
                     facet_row=row , height = 600)
    fig.update_yaxes(showticklabels=True , matches=None ,)
    fig.update_xaxes(showticklabels=True , matches=None)
    fig.show()

"""Gráficos de barras sobre as propoções dos dados, ou seja quantidade de cada classificação dentro das colunas(Gender,occupation BMI category e Sleep disorder)"""

plotly_countplot(data, "Gender", "Gender Distribution", "Gender", "Count")
plotly_countplot(data, "Occupation", "Occupation Distribution", "Occupation", "Count")
plotly_countplot(data, "BMI Category", "BMI Category Distribution", "BMI Category", "Count")
plotly_countplot(data, "Sleep Disorder", "Sleep Disorder Distribution", "Sleep Disorder", "Count")

"""Apontamentos sobre nível de estresse, duração do sono, qualidade do sono, IMC, passos por dia e nivel de atividade física por profissão."""

#Graficos de barras para comparação de atributos por ocupação
plotly_boxplot(data, ["Stress Level", "Sleep Duration", "Quality of Sleep"], "Occupation")
plotly_boxplot(data, ["Physical Activity Level", "BMI Category", "Daily Steps"], "Occupation")

"""Apontamentos sobre nível de estresse, duração do sono, qualidade do sono, IMC, passos por dia e nivel de atividade física por gênero."""

#Graficos de barras para comparação de atributos por genero
plotly_boxplot(data, ["Stress Level", "Sleep Duration", "Quality of Sleep"], "Gender")
plotly_boxplot(data, ["Physical Activity Level", "BMI Category", "Daily Steps"], "Gender")

"""apontamentos sobre nível de estresse, duração do sono e qualidade do sono por IMC"""

plotly_boxplot(data, ["Stress Level", "Sleep Duration", "Quality of Sleep"], "BMI Category")

"""Apontamentos sobre nível de estresse e duração do sono por qualidade do sono."""

plotly_boxplot(data, ["Stress Level", "Sleep Duration"], "Quality of Sleep")

plotly_scatter(data, "Age", "Sleep Duration",color="BMI Category")
plotly_scatter(data, "Quality of Sleep", "Sleep Duration",color="Physical Activity Level")
plotly_scatter(data, "Quality of Sleep", "Sleep Duration",color="Stress Level")

color_palette = {'Male': 'deepskyblue', 'Female': 'crimson'}

plt.figure(figsize=(10, 6))
sns.violinplot(x='Gender', y='Quality of Sleep', data=data,palette=color_palette)
plt.title('Distribuição da Qualidade do Sono por Gênero', fontsize=16)
plt.xlabel('Gênero', fontsize=12)
plt.ylabel('Quality of Sleep', fontsize=12)
plt.show()

fig = px.bar(data,
             x='Stress Level',
             y='Quality of Sleep',
             color='Stress Level',
             title='Relação entre o nível de estresse e a qualidade do sono',
             width=900, height=600,
             labels={
                 'Stress Level': 'Nível de Estresse',
                 'Quality of Sleep': 'Qualidade do Sono'
             }
            )
fig.show()

fig = px.bar(data,
             x='Stress Level',
             y='Sleep Duration',
             color='Stress Level',
             title='Relação entre o nível de estresse e a duração do sono',
             width=900, height=600,
             labels={
                 'Stress Level': 'Nível de Estresse',
                 'Sleep Duration': ' Duração do sono'
             }
            )
fig.show()

# @title Gender vs BMI Category

from matplotlib import pyplot as plt
import seaborn as sns
import pandas as pd
plt.subplots(figsize=(8, 8))
df_2dhist = pd.DataFrame({
    x_label: grp['BMI Category'].value_counts()
    for x_label, grp in data.groupby('Gender')
})
sns.heatmap(df_2dhist, cmap='viridis')
plt.xlabel('Gender')
_ = plt.ylabel('BMI Category')

"""#Pre-processamento dos dados

Nesse primeiro processamento os dados serão usados para uma avaliação de resultados, sem os dados tratados, mas em diferentes modelos.
"""

dataProcessada = data.copy()

dataProcessada = pd.concat([dataProcessada, dataProcessada['Blood Pressure'].str.split('/', expand=True)], axis=1).drop('Blood Pressure', axis=1)
dataProcessada = dataProcessada.rename(columns={0: 'BloodPressure_Upper', 1: 'BloodPressure_Lower'})
dataProcessada['BloodPressure_Upper'] = dataProcessada['BloodPressure_Upper'].astype(int)
dataProcessada['BloodPressure_Lower'] = dataProcessada['BloodPressure_Lower'].astype(int)

from sklearn import preprocessing
label_encoder = preprocessing.LabelEncoder()
dataProcessada['Gender'] = label_encoder.fit_transform(dataProcessada['Gender'])
dataProcessada['Occupation'] = label_encoder.fit_transform(dataProcessada['Occupation'])
dataProcessada['BMI Category'] = label_encoder.fit_transform(dataProcessada['BMI Category'])
dataProcessada['Sleep Disorder'] = label_encoder.fit_transform(dataProcessada['Sleep Disorder'])
dataProcessada.head()

"""Avaliação de correlações e plot gráfico"""

def corr_vis(corr) :
    mask = np.zeros_like(corr)
    mask[np.triu_indices_from(mask)] = True
    with sns.axes_style("white"):
        f, ax = plt.subplots(figsize=(10, 7))
        g = sns.heatmap(corr, mask=mask, vmax=.3, square=True, annot=True, cmap='coolwarm')
        g.set_xticklabels(g.get_xticklabels(), rotation = 90, fontsize = 10)

num_corr = dataProcessada.drop('Person ID', axis=1).corr()
corr_vis(dataProcessada.drop('Person ID', axis=1).corr())

"""#Extração de Padrões (treino dos modelos)"""

#separacao da base em hold-out
from sklearn.model_selection import train_test_split

X = dataProcessada.drop(['Person ID', 'Sleep Disorder'], axis=1)
y = dataProcessada['Sleep Disorder']

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)

#normalização

from sklearn.preprocessing import StandardScaler

scaler_d = StandardScaler()
X_train_scaled = scaler_d.fit_transform(X_train)
X_test_scaled = scaler_d.transform(X_test)

#Regressao Logistica
from sklearn.linear_model import LogisticRegression

# Create the models
regressaoLogistica = LogisticRegression()

# Fit the models
regressaoLogistica.fit(X_train_scaled, y_train)

#RandomForest
from sklearn.ensemble import RandomForestClassifier
randomForest = RandomForestClassifier()
randomForest.fit(X_train_scaled, y_train)

#GradientBoosting
from sklearn.ensemble import GradientBoostingClassifier
xgb = GradientBoostingClassifier()
xgb.fit(X_train_scaled, y_train)

#Rede Neural
from sklearn.neural_network import MLPClassifier # importação do modelo de rede neural MLPClassifier do scikit-learn
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error # importação das métricas de avaliação do modelo

n_epochs = 5000 #definição do numero de epocas
rede = MLPClassifier(hidden_layer_sizes=(11,), random_state=1, activation='relu', solver='adam', alpha=0.0001) #definição da rede neural

#treino da rede pelo numero de epocas definido e resultado de cada iteração
for epoch in range(n_epochs):
    rede.partial_fit(X_train_scaled, y_train, classes=np.unique(y_train))
    predito =  rede.predict(X_test_scaled)


    #validação do modelo
    print(f"Epoch {epoch + 1}/{n_epochs} - Score: {rede.score(X_test_scaled, y_test)}")

"""#Avaliação dos Modelos 1
Abaixo estão os resultados que os modelos obtiveram (f1-score), que se aproximam dos projetos que temos como comparação, vale ressaltar que o pre-processamento também foi identico ao projeto que estamos comparando, para se obter uma métrica que possa ser usada para compararmos com o nosso modelo desenvolvido.
"""

print("Regressao Logistica")
print(regressaoLogistica.score(X_test_scaled, y_test))
r1 = regressaoLogistica.score(X_test_scaled, y_test)
print("Random Forest")
print(randomForest.score(X_test_scaled, y_test))
r2 = randomForest.score(X_test_scaled, y_test)
print("Gradient Boosting")
print(xgb.score(X_test_scaled, y_test))
r3 = xgb.score(X_test_scaled, y_test)
print("Rede Neural")
print(rede.score(X_test_scaled, y_test))
r4 = rede.score(X_test_scaled, y_test)

"""# Visualização dos resultados dos modelos usando outras métricas de precisão:
Metrics: precision, recall, f1-score, support
"""

from sklearn.metrics import accuracy_score
import plotly.express as px
colors = px.colors.sequential.Plasma_r

def plot_classification_report(report, title):
    lines = report.split('\n')[2:-5]
    classes = []
    precision = []
    recall = []
    f1_score = []
    support = []
    for line in lines:
        row_data = line.split()
        classes.append(row_data[0])
        precision.append(float(row_data[1]))
        recall.append(float(row_data[2]))
        f1_score.append(float(row_data[3]))
        support.append(int(row_data[4]))

from sklearn.metrics import classification_report

regressorReport = classification_report(y_test, regressaoLogistica.predict(X_test_scaled))
randomForestReport = classification_report(y_test, randomForest.predict(X_test_scaled))
xgbReport = classification_report(y_test, xgb.predict(X_test_scaled))
redeReport = classification_report(y_test, predito)

print("Regressao Logistica")
print(regressorReport)
print("Random Forest")
print(randomForestReport)
print("Gradient Boosting")
print(xgbReport)
print("Rede Neural")
print(redeReport)

"""#Matriz de confusão, abaixo temos a matriz de confusão dos modelos testados"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

linearPredict = regressaoLogistica.predict(X_test_scaled)
randomForestPredict = randomForest.predict(X_test_scaled)
xgbPredict = xgb.predict(X_test_scaled)
redePredict = rede.predict(X_test_scaled)

cmlinear = confusion_matrix(y_test, linearPredict)
cmrandomForest = confusion_matrix(y_test, randomForestPredict)
cmxgb = confusion_matrix(y_test, xgbPredict)
cmrede = confusion_matrix(y_test, redePredict)

y_names = ['Apnea', 'Insomnia', 'No Disorder']

disp_linear = ConfusionMatrixDisplay(confusion_matrix=cmlinear, display_labels=y_names)
disp_randomForest = ConfusionMatrixDisplay(confusion_matrix=cmrandomForest, display_labels=y_names)
disp_xgb = ConfusionMatrixDisplay(confusion_matrix=cmxgb, display_labels=y_names)
disp_rede = ConfusionMatrixDisplay(confusion_matrix=cmrede, display_labels=y_names)

disp_linear.plot()
plt.title("Matriz de Confusão - Regressão Logística")
plt.show()

disp_randomForest.plot()
plt.title("Matriz de Confusão - Random Forest")
plt.show()

disp_xgb.plot()
plt.title("Matriz de Confusão - Gradient Boosting")
plt.show()

disp_rede.plot()
plt.title("Matriz de Confusão - Rede Neural")
plt.show()

"""#Pre-Processamento 2
A partir dessa parte do código passamos a desenvolver modelos que possam competir em performace com o projeto que estamos comparando.
"""

# Cópia dos dados em dataProcessada2
dataProcessada2 = data.copy()

"""Abaixo estão os tratamentos aplicados nos dados, a razão é manter a base normalizada
1. primeiro pressão sanguínea, de forma simples vamos tranformar a pressão sanguínea dividindo em pressão sistólica(BloodPressure_Upper) e pressão diastólica(BloodPressure_Lower), e converter para int.

"""

dataProcessada2 = pd.concat([dataProcessada2, dataProcessada2['Blood Pressure'].str.split('/', expand=True)], axis=1).drop('Blood Pressure', axis=1)
dataProcessada2 = dataProcessada2.rename(columns={0: 'BloodPressure_Upper', 1: 'BloodPressure_Lower'})
dataProcessada2['BloodPressure_Upper'] = dataProcessada2['BloodPressure_Upper'].astype(int)
dataProcessada2['BloodPressure_Lower'] = dataProcessada2['BloodPressure_Lower'].astype(int)

"""Alguns campos da coluna BMI Category apresentam o classficação "peso normal"(Normal Weight), entretanto também temos a classificação "normal"(Normal), para manter o padrão vamos deixar o valor "peso normal" como "normal"
"""

dataProcessada2['BMI Category'] = dataProcessada2['BMI Category'].replace('Normal Weight', 'Normal')

"""Label Encoding: A função LabelEncoder converte categorias (valores textuais) em números inteiros. Por exemplo, se a coluna 'Sleep Disorder' tem valores como 'Insomnia', 'Sleep Apnea', 'Narcolepsy', etc., o LabelEncoder transformará esses valores em números como 0, 1, 2, etc."""

from sklearn import preprocessing

label_encoder = preprocessing.LabelEncoder()
dataProcessada2['Sleep Disorder'] = label_encoder.fit_transform(dataProcessada2['Sleep Disorder'])

"""Aplicando o OneHotEncoder para as colunas fields BMI category, occupation, gender.
Motivo:
Para resolver isso iremos utilizar o hot encoding (ou one-hot encoding), que é uma técnica comum para transformar atributos categóricos em uma representação numérica. Ele cria colunas binárias (0 ou 1/true or false) para cada categoria de um atributo. Dessa forma evitamos que uma errônea hierarquia seja interpretada pelo algoritmo.

"""

from sklearn.preprocessing import OneHotEncoder

# Select categorical columns for one-hot encoding
categorical_cols = ['BMI Category', 'Occupation', 'Gender']

# Create OneHotEncoder object
encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)

# Fit and transform the categorical columns
encoded_data = encoder.fit_transform(dataProcessada2[categorical_cols])

# Create a DataFrame from the encoded data
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_cols))

# Concatenate the encoded DataFrame with the original DataFrame (dropping the original categorical columns)
dataProcessada2 = pd.concat([dataProcessada2.drop(categorical_cols, axis=1), encoded_df], axis=1)

# Now 'dataProcessada2' contains one-hot encoded columns for 'BMI Category', 'Occupation', and 'Gender'
dataProcessada2.head()

dataProcessada2.columns

"""#Extração de Padrões (treino dos modelos) 2"""

#separacao da base em hold-out
from sklearn.model_selection import train_test_split

X = dataProcessada2.drop(['Person ID', 'Sleep Disorder'], axis=1)
y = dataProcessada2['Sleep Disorder']

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)

#normalização

from sklearn.preprocessing import StandardScaler

scaler_d = StandardScaler()
X_train_scaled = scaler_d.fit_transform(X_train)
X_test_scaled = scaler_d.transform(X_test)

#Regressao Logistica
from sklearn.linear_model import LogisticRegression

# Create the models
regressaoLogistica = LogisticRegression()

# Fit the models
regressaoLogistica.fit(X_train_scaled, y_train)

#RandomForest
from sklearn.ensemble import RandomForestClassifier
randomForest = RandomForestClassifier()
randomForest.fit(X_train_scaled, y_train)

#GradientBoosting
from sklearn.ensemble import GradientBoostingClassifier
xgb = GradientBoostingClassifier()
xgb.fit(X_train_scaled, y_train)

#Rede Neural
from sklearn.neural_network import MLPClassifier # importação do modelo de rede neural MLPClassifier do scikit-learn
from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error # importação das métricas de avaliação do modelo

n_epochs = 5000 #definição do numero de epocas
rede = MLPClassifier(hidden_layer_sizes=(11,), random_state=1, activation='relu', solver='adam', alpha=0.0001) #definição da rede neural

#treino da rede pelo numero de epocas definido e resultado de cada iteração
for epoch in range(n_epochs):
    rede.partial_fit(X_train_scaled, y_train, classes=np.unique(y_train))
    predito =  rede.predict(X_test_scaled)


    #validação do modelo
    print(f"Epoch {epoch + 1}/{n_epochs} - Score: {rede.score(X_test_scaled, y_test)}")

"""#Avaliação dos Modelos 2
Abaixo estão os resultados que os modelos obtiveram (f1-score), com os dados devidamente tratados

"""

print("Regressao Logistica")
print(regressaoLogistica.score(X_test_scaled, y_test))
r5 = regressaoLogistica.score(X_test_scaled, y_test)
print("Random Forest")
print(randomForest.score(X_test_scaled, y_test))
r6 = randomForest.score(X_test_scaled, y_test)
print("Gradient Boosting")
print(xgb.score(X_test_scaled, y_test))
r7 =  xgb.score(X_test_scaled, y_test)
print("Rede Neural")
print(rede.score(X_test_scaled, y_test))
r8 =  rede.score(X_test_scaled, y_test)

from sklearn.metrics import accuracy_score
import plotly.express as px
colors = px.colors.sequential.Plasma_r

def plot_classification_report(report, title):
    lines = report.split('\n')[2:-5]
    classes = []
    precision = []
    recall = []
    f1_score = []
    support = []
    for line in lines:
        row_data = line.split()
        classes.append(row_data[0])
        precision.append(float(row_data[1]))
        recall.append(float(row_data[2]))
        f1_score.append(float(row_data[3]))
        support.append(int(row_data[4]))

from sklearn.metrics import classification_report

regressorReport = classification_report(y_test, regressaoLogistica.predict(X_test_scaled))
randomForestReport = classification_report(y_test, randomForest.predict(X_test_scaled))
xgbReport = classification_report(y_test, xgb.predict(X_test_scaled))
redeReport = classification_report(y_test, predito)

print("Regressao Logistica")
print(regressorReport)
print("Random Forest")
print(randomForestReport)
print("Gradient Boosting")
print(xgbReport)
print("Rede Neural")
print(redeReport)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

linearPredict = regressaoLogistica.predict(X_test_scaled)
randomForestPredict = randomForest.predict(X_test_scaled)
xgbPredict = xgb.predict(X_test_scaled)
redePredict = rede.predict(X_test_scaled)

cmlinear = confusion_matrix(y_test, linearPredict)
cmrandomForest = confusion_matrix(y_test, randomForestPredict)
cmxgb = confusion_matrix(y_test, xgbPredict)
cmrede = confusion_matrix(y_test, redePredict)

y_names = ['Apnea', 'Insomnia', 'No Disorder']

disp_linear = ConfusionMatrixDisplay(confusion_matrix=cmlinear, display_labels=y_names)
disp_randomForest = ConfusionMatrixDisplay(confusion_matrix=cmrandomForest, display_labels=y_names)
disp_xgb = ConfusionMatrixDisplay(confusion_matrix=cmxgb, display_labels=y_names)
disp_rede = ConfusionMatrixDisplay(confusion_matrix=cmrede, display_labels=y_names)

disp_linear.plot()
plt.title("Matriz de Confusão - Regressão Logística")
plt.show()

disp_randomForest.plot()
plt.title("Matriz de Confusão - Random Forest")
plt.show()

disp_xgb.plot()
plt.title("Matriz de Confusão - Gradient Boosting")
plt.show()

disp_rede.plot()
plt.title("Matriz de Confusão - Rede Neural")
plt.show()

"""#Extração de padrões Kfold 1"""

from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier


# Create a KFold object with 5 splits
#kf = KFold(n_splits=10, shuffle=True, random_state=42)
X = dataProcessada.drop(['Person ID', 'Sleep Disorder'], axis=1)
y = dataProcessada['Sleep Disorder']

scaler_d = StandardScaler()
X_train_scaled = scaler_d.fit_transform(X)

lrmodel = LogisticRegression()
lr_scores = cross_val_score(lrmodel, X_train_scaled, y, cv=10)
print("Logistic Regression Cross-Validation Scores:", lr_scores)
print("Mean Score:", lr_scores.mean())

rfmodel = RandomForestClassifier()
rf_scores = cross_val_score(rfmodel, X_train_scaled, y, cv=10)
print("Random Forest Cross-Validation Scores:", rf_scores)
print("Mean Score:", rf_scores.mean())

xgbmodel = GradientBoostingClassifier()
xgb_scores = cross_val_score(xgbmodel, X_train_scaled, y, cv=10)
print("Gradient Boosting Cross-Validation Scores:", xgb_scores)
print("Mean Score:", xgb_scores.mean())

nrmodel = MLPClassifier(hidden_layer_sizes=(11,), random_state=1, activation='relu', solver='adam', alpha=0.0001)
nr_scores = cross_val_score(nrmodel, X_train_scaled, y, cv=10)
print("Neural Network Cross-Validation Scores:", nr_scores)
print("Mean Score:", nr_scores.mean())

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

linearPredict = regressaoLogistica.predict(X_test_scaled)
randomForestPredict = randomForest.predict(X_test_scaled)
xgbPredict = xgb.predict(X_test_scaled)
redePredict = rede.predict(X_test_scaled)

cmlinear = confusion_matrix(y_test, linearPredict)
cmrandomForest = confusion_matrix(y_test, randomForestPredict)
cmxgb = confusion_matrix(y_test, xgbPredict)
cmrede = confusion_matrix(y_test, redePredict)

y_names = ['Apnea', 'Insomnia', 'No Disorder']

disp_linear = ConfusionMatrixDisplay(confusion_matrix=cmlinear, display_labels=y_names)
disp_randomForest = ConfusionMatrixDisplay(confusion_matrix=cmrandomForest, display_labels=y_names)
disp_xgb = ConfusionMatrixDisplay(confusion_matrix=cmxgb, display_labels=y_names)
disp_rede = ConfusionMatrixDisplay(confusion_matrix=cmrede, display_labels=y_names)

disp_linear.plot()
plt.title("Matriz de Confusão - Regressão Logística")
plt.show()

disp_randomForest.plot()
plt.title("Matriz de Confusão - Random Forest")
plt.show()

disp_xgb.plot()
plt.title("Matriz de Confusão - Gradient Boosting")
plt.show()

disp_rede.plot()
plt.title("Matriz de Confusão - Rede Neural")
plt.show()

# Dados para o gráfico
modelos = ['Regressão Logística', 'Random Forest', 'Gradient Boosting', 'Rede Neural']
precisoes = [lr_scores.mean(), rf_scores.mean(), xgb_scores.mean(), nr_scores.mean()]
cores = ['blue', 'green', 'red', 'purple']

# Crie o gráfico de barras
plt.figure(figsize=(10, 6))
bars = plt.bar(modelos, precisoes, color=['blue', 'green', 'red', 'purple'])

# Adicione rótulos e título
plt.xlabel('Modelos')
plt.ylabel('Precisão')
plt.title('Comparação da Precisão dos Modelos - Avaliação 1')

# Adicione os valores de precisão em porcentagem acima de cada barra
for bar, precisao in zip(bars, precisoes):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{precisao * 100:.2f}%', ha='center', va='bottom')

# Exiba o gráfico
plt.tight_layout()
plt.show()

"""#Extração de padrões Kfold 2"""

from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.neural_network import MLPClassifier


# Create a KFold object with 5 splits
#kf = KFold(n_splits=10, shuffle=True, random_state=42)
X = dataProcessada2.drop(['Person ID', 'Sleep Disorder'], axis=1)
y = dataProcessada2['Sleep Disorder']

scaler_d = StandardScaler()
X_train_scaled = scaler_d.fit_transform(X)

lrmodel = LogisticRegression()
lr_scores = cross_val_score(lrmodel, X_train_scaled, y, cv=10)
print("Logistic Regression Cross-Validation Scores:", lr_scores)
print("Mean Score:", lr_scores.mean())

rfmodel = RandomForestClassifier()
rf_scores = cross_val_score(rfmodel, X_train_scaled, y, cv=10)
print("Random Forest Cross-Validation Scores:", rf_scores)
print("Mean Score:", rf_scores.mean())

xgbmodel = GradientBoostingClassifier()
xgb_scores = cross_val_score(xgbmodel, X_train_scaled, y, cv=10)
print("Gradient Boosting Cross-Validation Scores:", xgb_scores)
print("Mean Score:", xgb_scores.mean())

nrmodel = MLPClassifier(hidden_layer_sizes=(11,), random_state=1, activation='relu', solver='adam', alpha=0.0001)
nr_scores = cross_val_score(nrmodel, X_train_scaled, y, cv=10)
print("Neural Network Cross-Validation Scores:", nr_scores)
print("Mean Score:", nr_scores.mean())

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

linearPredict = regressaoLogistica.predict(X_test_scaled)
randomForestPredict = randomForest.predict(X_test_scaled)
xgbPredict = xgb.predict(X_test_scaled)
redePredict = rede.predict(X_test_scaled)

cmlinear = confusion_matrix(y_test, linearPredict)
cmrandomForest = confusion_matrix(y_test, randomForestPredict)
cmxgb = confusion_matrix(y_test, xgbPredict)
cmrede = confusion_matrix(y_test, redePredict)

y_names = ['Apnea', 'Insomnia', 'No Disorder']

disp_linear = ConfusionMatrixDisplay(confusion_matrix=cmlinear, display_labels=y_names)
disp_randomForest = ConfusionMatrixDisplay(confusion_matrix=cmrandomForest, display_labels=y_names)
disp_xgb = ConfusionMatrixDisplay(confusion_matrix=cmxgb, display_labels=y_names)
disp_rede = ConfusionMatrixDisplay(confusion_matrix=cmrede, display_labels=y_names)

disp_linear.plot()
plt.title("Matriz de Confusão - Regressão Logística")
plt.show()

disp_randomForest.plot()
plt.title("Matriz de Confusão - Random Forest")
plt.show()

disp_xgb.plot()
plt.title("Matriz de Confusão - Gradient Boosting")
plt.show()

disp_rede.plot()
plt.title("Matriz de Confusão - Rede Neural")
plt.show()

import matplotlib.pyplot as plt

# Dados para o gráfico
modelos = ['Regressão Logística', 'Random Forest', 'Gradient Boosting', 'Rede Neural']
precisoes = [lr_scores.mean(), rf_scores.mean(), xgb_scores.mean(), nr_scores.mean()]
cores = ['blue', 'green', 'red', 'purple']

# Crie o gráfico de barras
plt.figure(figsize=(10, 6))
bars = plt.bar(modelos, precisoes, color=['blue', 'green', 'red', 'purple'])

# Adicione rótulos e título
plt.xlabel('Modelos')
plt.ylabel('Precisão')
plt.title('Comparação da Precisão dos Modelos - Avaliação 2')

# Adicione os valores de precisão em porcentagem acima de cada barra
for bar, precisao in zip(bars, precisoes):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{precisao * 100:.2f}%', ha='center', va='bottom')

# Exiba o gráfico
plt.tight_layout()
plt.show()

"""#Keras"""

import keras
print(keras.__version__)

def train_and_evaluate_model(model):
    # Train the model
    model.fit(X_train_scaled, y_train, epochs=100, callbacks=callbacks)
    # Evaluate the model
    score = model.evaluate(X_test_scaled, y_test)
    print(f'Test loss: {score[0]}')
    print(f'Test accuracy: {score[1]}')

X = dataProcessada.drop(['Person ID', 'Sleep Disorder'], axis=1)
y = dataProcessada['Sleep Disorder']

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)

scaler_d = StandardScaler()
X_train_scaled = scaler_d.fit_transform(x_train)
X_test_scaled = scaler_d.transform(x_test)


callbacks = [
    keras.callbacks.EarlyStopping(monitor="loss", mode="min",patience=25),
]

# Define the Keras model
model1 = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(3, activation='softmax')  # 3 output classes for 'Sleep Disorder'
])

# Compile the model
model1.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model2 = keras.Sequential([
    keras.layers.Dense(12, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    keras.layers.Dense(6, activation='relu'),
    keras.layers.Dense(3, activation='softmax')  # 3 output classes for 'Sleep Disorder'
])

model2.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model3 = keras.Sequential([
    keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),
    keras.layers.MaxPooling1D(pool_size=2),
    keras.layers.Flatten(),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(3, activation='softmax')  # 3 output classes for 'Sleep Disorder'
])

model3.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model4 = keras.Sequential([
    keras.layers.LSTM(64, input_shape=(X_train_scaled.shape[1], 1)),
    keras.layers.Dense(3, activation='softmax')  # 3 output classes for 'Sleep Disorder'
])

model4.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model5 = keras.Sequential([
    keras.layers.GRU(64, input_shape=(X_train_scaled.shape[1], 1)),
    keras.layers.Dense(3, activation='softmax')
])

model5.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

train_and_evaluate_model(model1)
train_and_evaluate_model(model2)
train_and_evaluate_model(model3)
train_and_evaluate_model(model4)
train_and_evaluate_model(model5)

def train_and_evaluate_model(model, epochs, callbacks):
    # Train the model
    model.fit(X_train_scaled, y_train, epochs=epochs, callbacks=callbacks)
    # Evaluate the model
    score = model.evaluate(X_test_scaled, y_test)
    print(f'Test loss: {score[0]}')
    print(f'Test accuracy: {score[1]}')

#Como os 3 primeiros modelos tiveram um melhor resultado, havera uma segunda rodada de alterações a fim de buscar melhores resultados

callbacks1 = [
    keras.callbacks.EarlyStopping(monitor="accuracy", patience=4),
]

callbacks2 = [
    keras.callbacks.EarlyStopping(monitor="accuracy", patience=5),
]

callbacks3 = [
    keras.callbacks.EarlyStopping(monitor="loss", mode="min", patience=2),
]


model1.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model2.compile(optimizer='adagrad',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model3.compile(optimizer='adadelta',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

train_and_evaluate_model(model1, 30, callbacks1)
train_and_evaluate_model(model2, 100, callbacks2)
train_and_evaluate_model(model3, 100, callbacks3)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predict classes for the test set
y_pred = model1.predict(X_test_scaled)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pred_classes)

# Display confusion matrix
y_names = ['Apnea', 'Insomnia', 'No Disorder']  # Replace with actual class names
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=y_names)
disp.plot()
plt.title("Matriz de Confusão - Keras Model")
plt.show()

"""#Keras 2"""

import keras
print(keras.__version__)

def train_and_evaluate_model(model):
    # Train the model
    model.fit(X_train_scaled, y_train, epochs=100, callbacks=callbacks)
    # Evaluate the model
    score = model.evaluate(X_test_scaled, y_test)
    print(f'Test loss: {score[0]}')
    print(f'Test accuracy: {score[1]}')

# Assuming X_train_scaled, y_train, X_test_scaled, and y_test are already defined

X = dataProcessada2.drop(['Person ID', 'Sleep Disorder'], axis=1)
y = dataProcessada2['Sleep Disorder']

x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2)

scaler_d = StandardScaler()
X_train_scaled = scaler_d.fit_transform(x_train)
X_test_scaled = scaler_d.transform(x_test)

callbacks = [
    keras.callbacks.EarlyStopping(monitor="loss", mode="min", patience=15),
]

# Define the Keras model
model1 = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(3, activation='softmax')  # 3 output classes for 'Sleep Disorder'
])

# Compile the model
model1.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model2 = keras.Sequential([
    keras.layers.Dense(27, activation='relu', input_shape=(X_train_scaled.shape[1],)),
    keras.layers.Dense(9, activation='relu'),
    keras.layers.Dense(3, activation='softmax')  # 3 output classes for 'Sleep Disorder'
])

model2.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model3 = keras.Sequential([
    keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),
    keras.layers.MaxPooling1D(pool_size=2),
    keras.layers.Flatten(),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(3, activation='softmax')  # 3 output classes for 'Sleep Disorder'
])

model3.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model4 = keras.Sequential([
    keras.layers.LSTM(64, input_shape=(X_train_scaled.shape[1], 1)),
    keras.layers.Dense(3, activation='softmax')  # 3 output classes for 'Sleep Disorder'
])

model4.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model5 = keras.Sequential([
    keras.layers.GRU(64, input_shape=(X_train_scaled.shape[1], 1)),
    keras.layers.Dense(3, activation='softmax')
])

model5.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

train_and_evaluate_model(model1)
train_and_evaluate_model(model2)
train_and_evaluate_model(model3)
train_and_evaluate_model(model4)
train_and_evaluate_model(model5)

def train_and_evaluate_model(model, epochs, callbacks):
    # Train the model
    model.fit(X_train_scaled, y_train, epochs=epochs, callbacks=callbacks)
    # Evaluate the model
    score = model.evaluate(X_test_scaled, y_test)
    print(f'Test loss: {score[0]}')
    print(f'Test accuracy: {score[1]}')

#neste segundo teste, os modelos 1, 3 e 5 obtiveram uma maior acuracia, assim indo pra uma segunda fase de ajustes
callbacks1 = [
    keras.callbacks.EarlyStopping(monitor="accuracy", patience=4),
]

callbacks2 = [
    keras.callbacks.EarlyStopping(monitor="accuracy", patience=5),
]

callbacks3 = [
    keras.callbacks.EarlyStopping(monitor="loss", mode="min", patience=2),
]


model1.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model2.compile(optimizer='adagrad',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model3.compile(optimizer='adadelta',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

train_and_evaluate_model(model1, 30, callbacks1)
train_and_evaluate_model(model2, 150, callbacks2)
train_and_evaluate_model(model3, 150, callbacks3)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predict classes for the test set
y_pred = model2.predict(X_test_scaled)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pred_classes)

# Display confusion matrix
y_names = ['Apnea', 'Insomnia', 'No Disorder']  # Replace with actual class names
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=y_names)
disp.plot()
plt.title("Matriz de Confusão - Keras Model")
plt.show()

"""#Keras Kfold 1"""

import keras
print(keras.__version__)

from sklearn.model_selection import KFold

X = dataProcessada.drop(['Person ID', 'Sleep Disorder'], axis=1)
y = dataProcessada['Sleep Disorder']

# Define the Keras model
def create_model():
  model = keras.Sequential([
      keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1],)),
      keras.layers.Dense(32, activation='relu'),
      keras.layers.Dense(3, activation='softmax')
  ])
  model.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
  return model

# K-fold cross-validation
kf = KFold(n_splits=10, shuffle=True, random_state=42)
scores = []

for train_index, test_index in kf.split(X):
  X_train, X_test = X.iloc[train_index], X.iloc[test_index]
  y_train, y_test = y.iloc[train_index], y.iloc[test_index]

  scaler_d = StandardScaler()
  X_train_scaled = scaler_d.fit_transform(X_train)
  X_test_scaled = scaler_d.transform(X_test)

  model = create_model()
  model.fit(X_train_scaled, y_train, epochs=30, verbose=0)
  score = model.evaluate(X_test_scaled, y_test, verbose=0)
  scores.append(score[1])

print("Cross-Validation Accuracy Scores:", scores)
print("Mean Accuracy:", np.mean(scores))
kk1=np.mean(scores)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predict classes for the test set
y_pred = model.predict(X_test_scaled)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pred_classes)

# Display confusion matrix
y_names = ['Apnea', 'Insomnia', 'No Disorder']  # Replace with actual class names
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=y_names)
disp.plot()
plt.title("Matriz de Confusão - Keras Model")
plt.show()

"""#Keras Kfold 2"""

import keras
print(keras.__version__)

from sklearn.model_selection import KFold

X = dataProcessada2.drop(['Person ID', 'Sleep Disorder'], axis=1)
y = dataProcessada2['Sleep Disorder']

# Define the Keras model
def create_model():
  model = keras.Sequential([
      keras.layers.Dense(64, activation='relu', input_shape=(X.shape[1],)),
      keras.layers.Dense(32, activation='relu'),
      keras.layers.Dense(3, activation='softmax')
  ])
  model.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
  return model

# K-fold cross-validation
kf = KFold(n_splits=10, shuffle=True, random_state=42)
scores = []

for train_index, test_index in kf.split(X):
  X_train, X_test = X.iloc[train_index], X.iloc[test_index]
  y_train, y_test = y.iloc[train_index], y.iloc[test_index]

  scaler_d = StandardScaler()
  X_train_scaled = scaler_d.fit_transform(X_train)
  X_test_scaled = scaler_d.transform(X_test)

  model = create_model()
  model.fit(X_train_scaled, y_train, epochs=30, verbose=0)
  score = model.evaluate(X_test_scaled, y_test, verbose=0)
  scores.append(score[1])

print("Cross-Validation Accuracy Scores:", scores)
print("Mean Accuracy:", np.mean(scores))
kk2=np.mean(scores)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Predict classes for the test set
y_pred = model.predict(X_test_scaled)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pred_classes)

# Display confusion matrix
y_names = ['Apnea', 'Insomnia', 'No Disorder']  # Replace with actual class names
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=y_names)
disp.plot()
plt.title("Matriz de Confusão - Keras Model")
plt.show()

"""#Gráfico comparativo dos resultados das precisões dos modelos Hold-out"""

import matplotlib.pyplot as plt
import numpy as np

# Dados dos modelos (substitua com seus próprios dados)
modelos = ['Regressão Logística', 'Random Forest', 'Gradient Boosting', 'Rede Neural']
precisoes = [r1,r2,r3,r4]  # Substitua com suas precisões

# Crie o gráfico de barras
plt.figure(figsize=(10, 6))
bars = plt.bar(modelos, precisoes, color=['blue', 'green', 'red', 'purple'])

# Adicione rótulos e título
plt.xlabel('Modelos')
plt.ylabel('Precisão')
plt.title('Comparação da Precisão dos Modelos - Avaliação 1')

# Adicione os valores de precisão em porcentagem acima de cada barra
for bar, precisao in zip(bars, precisoes):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{precisao * 100:.2f}%', ha='center', va='bottom')

# Exiba o gráfico
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Dados dos modelos (substitua com seus próprios dados)
modelos = ['Regressão Logística', 'Random Forest', 'Gradient Boosting', 'Rede Neural']
precisoes = [r5,r6,r7,r8]  # Substitua com suas precisões

# Crie o gráfico de barras
plt.figure(figsize=(10, 6))
bars = plt.bar(modelos, precisoes, color=['blue', 'green', 'red', 'purple'])

# Adicione rótulos e título
plt.xlabel('Modelos')
plt.ylabel('Precisão')
plt.title('Comparação da Precisão dos Modelos - Avaliação 2')

# Adicione os valores de precisão em porcentagem acima de cada barra
for bar, precisao in zip(bars, precisoes):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{precisao * 100:.2f}%', ha='center', va='bottom')

# Exiba o gráfico
plt.tight_layout()
plt.show()

"""#Gráfico comparativo dos resultados das precisões dos modelos Keras, com k-fold"""

import matplotlib.pyplot as plt
import numpy as np

# Dados dos modelos (substitua com seus próprios dados)
modelos = ['Keras 1-K-fold ', 'Keras 2-K-fold']
precisoes = [kk1,kk2]  # Substitua com suas precisões

# Crie o gráfico de barras
plt.figure(figsize=(10, 6))
bars = plt.bar(modelos, precisoes, color=['blue', 'red'])

# Adicione rótulos e título
plt.xlabel('Modelos')
plt.ylabel('Precisão')
plt.title('Comparação da Precisão dos Modelos')

# Adicione os valores de precisão em porcentagem acima de cada barra
for bar, precisao in zip(bars, precisoes):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{precisao * 100:.2f}%', ha='center', va='bottom')

# Exiba o gráfico
plt.tight_layout()
plt.show()

"""# Keras, gráficos comparativos sem k-fold"""

import matplotlib.pyplot as plt
import numpy as np

# Função para treinar e avaliar o modelo, retornando as métricas
def train_and_evaluate_model(model, model_name):
    # Treina o modelo
    model.fit(X_train_scaled, y_train, epochs=100, callbacks=callbacks, verbose=0)
    # Avalia o modelo
    score = model.evaluate(X_test_scaled, y_test, verbose=0)
    print(f'{model_name} - Test loss: {score[0]}')
    print(f'{model_name} - Test accuracy: {score[1]}')
    return score[0], score[1]

# Definindo os modelos e seus nomes
models = {
    'Model 1': model1,
    'Model 2': model2,
    'Model 3': model3,
    'Model 4': model4,
    'Model 5': model5
}

# Listas para armazenar as perdas e acurácias
test_losses = []
test_accuracies = []

# Treina e avalia cada modelo, armazenando os resultados
for model_name, model in models.items():
    loss, accuracy = train_and_evaluate_model(model, model_name)
    test_losses.append(loss)
    test_accuracies.append(accuracy)

# Cria um gráfico comparativo
plt.figure(figsize=(14, 6))

# Gráfico de Test Loss
#plt.subplot(1, 2, 1)
#bars1 = plt.bar(models.keys(), test_losses, color='orange')
#plt.xlabel('Modelos')
#plt.ylabel('Test Loss')
#plt.title('Comparação de Test Loss dos Modelos')
#for bar, loss in zip(bars1, test_losses):
#    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{loss:.4f}', ha='center', va='bottom')

# Gráfico de Test Accuracy
plt.subplot(1, 2, 2)
bars2 = plt.bar(models.keys(), test_accuracies, color='blue')
plt.xlabel('Modelos')
plt.ylabel('Test Accuracy')
plt.title('Comparação de Test Accuracy dos Modelos')
for bar, accuracy in zip(bars2, test_accuracies):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{accuracy * 100:.2f}%', ha='center', va='bottom')

plt.tight_layout()
plt.show()

#TOP 3 melhores

import matplotlib.pyplot as plt
import numpy as np

# Função para treinar e avaliar o modelo, com argumentos adicionais para epochs e callbacks
def train_and_evaluate_model(model, epochs, callbacks, model_name):
    # Treina o modelo
    model.fit(X_train_scaled, y_train, epochs=epochs, callbacks=callbacks, verbose=0)
    # Avalia o modelo
    score = model.evaluate(X_test_scaled, y_test, verbose=0)
    print(f'{model_name} - Test loss: {score[0]}')
    print(f'{model_name} - Test accuracy: {score[1]}')
    return score[0], score[1]

# Definindo os novos callbacks
callbacks1 = [
    keras.callbacks.EarlyStopping(monitor="accuracy", patience=4),
]

callbacks2 = [
    keras.callbacks.EarlyStopping(monitor="accuracy", patience=5),
]

callbacks3 = [
    keras.callbacks.EarlyStopping(monitor="loss", mode="min", patience=2),
]

# Compilando os modelos com novos otimizadores
model1.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model2.compile(optimizer='adagrad',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model3.compile(optimizer='adadelta',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Listas para armazenar as perdas e acurácias
test_losses = []
test_accuracies = []

# Treina e avalia cada modelo, armazenando os resultados
models = {
    'Model 1': (model1, 30, callbacks1),
    'Model 2': (model2, 100, callbacks2),
    'Model 3': (model3, 100, callbacks3)
}

for model_name, (model, epochs, callbacks) in models.items():
    loss, accuracy = train_and_evaluate_model(model, epochs, callbacks, model_name)
    test_losses.append(loss)
    test_accuracies.append(accuracy)

# Cria um gráfico comparativo
plt.figure(figsize=(14, 6))

# Gráfico de Test Loss
# plt.subplot(1, 2, 1)
# bars1 = plt.bar(models.keys(), test_losses, color='orange')
# plt.xlabel('Modelos')
# plt.ylabel('Test Loss')
# plt.title('Comparação de Test Loss dos Modelos - Segunda Rodada')
# for bar, loss in zip(bars1, test_losses):
#     plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{loss:.4f}', ha='center', va='bottom')

# Gráfico de Test Accuracy
plt.subplot(1, 2, 2)
bars2 = plt.bar(models.keys(), test_accuracies, color='blue')
plt.xlabel('Modelos')
plt.ylabel('Test Accuracy')
plt.title('Comparação de Test Accuracy dos Modelos - Segunda Rodada')
for bar, accuracy in zip(bars2, test_accuracies):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{accuracy * 100:.2f}%', ha='center', va='bottom')

plt.tight_layout()
plt.show()

"""# Keras 2, gráficos comparativos sem k-fold"""

import matplotlib.pyplot as plt
import numpy as np

# Função para treinar e avaliar o modelo, retornando as métricas
def train_and_evaluate_model(model, model_name):
    # Treina o modelo
    model.fit(X_train_scaled, y_train, epochs=100, callbacks=callbacks, verbose=0)
    # Avalia o modelo
    score = model.evaluate(X_test_scaled, y_test, verbose=0)
    print(f'{model_name} - Test loss: {score[0]}')
    print(f'{model_name} - Test accuracy: {score[1]}')
    return score[0], score[1]

# Definindo os modelos e seus nomes
models = {
    'Model 1': model1,
    'Model 2': model2,
    'Model 3': model3,
    'Model 4': model4,
    'Model 5': model5
}

# Listas para armazenar as perdas e acurácias
test_losses = []
test_accuracies = []

# Treina e avalia cada modelo, armazenando os resultados
for model_name, model in models.items():
    loss, accuracy = train_and_evaluate_model(model, model_name)
    test_losses.append(loss)
    test_accuracies.append(accuracy)

# Cria um gráfico comparativo
plt.figure(figsize=(14, 6))

# Gráfico de Test Loss
# plt.subplot(1, 2, 1)
# bars1 = plt.bar(models.keys(), test_losses, color='orange')
# plt.xlabel('Modelos')
# plt.ylabel('Test Loss')
# plt.title('Comparação de Test Loss dos Modelos - dataProcessada2')
# for bar, loss in zip(bars1, test_losses):
#     plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{loss:.4f}', ha='center', va='bottom')

# Gráfico de Test Accuracy
plt.subplot(1, 2, 2)
bars2 = plt.bar(models.keys(), test_accuracies, color='blue')
plt.xlabel('Modelos')
plt.ylabel('Test Accuracy')
plt.title('Comparação de Test Accuracy dos Modelos - dataProcessada')
for bar, accuracy in zip(bars2, test_accuracies):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{accuracy * 100:.2f}%', ha='center', va='bottom')

plt.tight_layout()
plt.show()

#TOP 3

import matplotlib.pyplot as plt
import numpy as np

# Função para treinar e avaliar o modelo, retornando as métricas
def train_and_evaluate_model(model, epochs, callbacks, model_name):
    # Treina o modelo
    model.fit(X_train_scaled, y_train, epochs=epochs, callbacks=callbacks, verbose=0)
    # Avalia o modelo
    score = model.evaluate(X_test_scaled, y_test, verbose=0)
    print(f'{model_name} - Test loss: {score[0]}')
    print(f'{model_name} - Test accuracy: {score[1]}')
    return score[0], score[1]

# Definindo os novos callbacks
callbacks1 = [
    keras.callbacks.EarlyStopping(monitor="accuracy", patience=4),
]

callbacks2 = [
    keras.callbacks.EarlyStopping(monitor="accuracy", patience=5),
]

callbacks3 = [
    keras.callbacks.EarlyStopping(monitor="loss", mode="min", patience=2),
]

# Compilando os modelos com os ajustes necessários
model1.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model3.compile(optimizer='adadelta',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model5.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Listas para armazenar as perdas e acurácias
test_losses = []
test_accuracies = []

# Dicionário para armazenar os modelos, epochs e callbacks
models = {
    'Model 1': (model1, 30, callbacks1),
    'Model 3': (model3, 150, callbacks3),
    'Model 5': (model5, 150, callbacks2)
}

# Treina e avalia cada modelo, armazenando os resultados
for model_name, (model, epochs, callbacks) in models.items():
    loss, accuracy = train_and_evaluate_model(model, epochs, callbacks, model_name)
    test_losses.append(loss)
    test_accuracies.append(accuracy)

# Cria um gráfico comparativo
plt.figure(figsize=(14, 6))

# Gráfico de Test Loss
# plt.subplot(1, 2, 1)
# bars1 = plt.bar(models.keys(), test_losses, color='orange')
# plt.xlabel('Modelos')
# plt.ylabel('Test Loss')
# plt.title('Comparação de Test Loss dos Modelos - Segunda Rodada')
# for bar, loss in zip(bars1, test_losses):
#     plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{loss:.4f}', ha='center', va='bottom')

# Gráfico de Test Accuracy
plt.subplot(1, 2, 2)
bars2 = plt.bar(models.keys(), test_accuracies, color='blue')
plt.xlabel('Modelos')
plt.ylabel('Test Accuracy')
plt.title('Comparação de Test Accuracy dos Modelos - Segunda Rodada')
for bar, accuracy in zip(bars2, test_accuracies):
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01, f'{accuracy * 100:.2f}%', ha='center', va='bottom')

plt.tight_layout()
plt.show()